"""
K-Stay AI Service
OpenAI ê¸°ë°˜ AI ê¸°ëŠ¥ ì²˜ë¦¬
"""

import streamlit as st
from typing import Optional, Dict, List, Tuple
import json

# OpenAI í´ë¼ì´ì–¸íŠ¸ (ì‹¤ì œ ë°°í¬ ì‹œ í™œì„±í™”)
# from openai import OpenAI
# from config.settings import OPENAI_API_KEY


class AIService:
    """AI ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        # ì‹¤ì œ ë°°í¬ ì‹œ ì•„ë˜ ì£¼ì„ í•´ì œ
        # self.client = OpenAI(api_key=OPENAI_API_KEY)
        self.model = "gpt-4o"  # ë˜ëŠ” "gpt-4o-mini"
    
    def validate_narrative(self, narrative: str, validation_prompt: str, scenario_context: Dict) -> Dict:
        """
        ì‚¬ì—° ë‚´ìš© ê²€ì¦ ë° í”¼ë“œë°±
        
        Args:
            narrative: ì‚¬ìš©ìê°€ ì‘ì„±í•œ ì‚¬ì—°
            validation_prompt: ì‹œë‚˜ë¦¬ì˜¤ë³„ ê²€ì¦ í”„ë¡¬í”„íŠ¸
            scenario_context: ì‹œë‚˜ë¦¬ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            
        Returns:
            ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # =================================================================
            # ì‹¤ì œ OpenAI ì—°ë™ ì½”ë“œ (ë°°í¬ ì‹œ í™œì„±í™”)
            # =================================================================
            """
            system_prompt = f'''
            {validation_prompt}
            
            ì‘ë‹µ í˜•ì‹ (JSON):
            {{
                "is_valid": true/false,
                "score": 1-10,
                "issues": ["ë¬¸ì œì 1", "ë¬¸ì œì 2"],
                "suggestions": ["ê°œì„ ì 1", "ê°œì„ ì 2"],
                "improved_version": "ê°œì„ ëœ ë²„ì „ (ë¬¸ì œê°€ ìˆì„ ê²½ìš°)"
            }}
            '''
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"ë‹¤ìŒ ë‚´ìš©ì„ ê²€í† í•´ì£¼ì„¸ìš”:\n\n{narrative}"}
                ],
                response_format={"type": "json_object"}
            )
            
            return json.loads(response.choices[0].message.content)
            """
            # =================================================================
            # ê°œë°œìš© ëª©ì—… ì½”ë“œ
            # =================================================================
            # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ê²€ì¦
            issues = []
            suggestions = []
            score = 8
            
            if len(narrative) < 100:
                issues.append("ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")
                suggestions.append("ìµœì†Œ 200ì ì´ìƒ ì‘ì„±í•´ì£¼ì„¸ìš”.")
                score -= 2
            
            if "ì·¨ì—… í™•ì •" in narrative or "ë‚´ì •" in narrative:
                issues.append("'ì·¨ì—… í™•ì •', 'ë‚´ì •' ë“±ì˜ í‘œí˜„ì€ D-10 ë¹„ìì— ë¶€ì í•©í•©ë‹ˆë‹¤.")
                suggestions.append("'êµ¬ì§ í™œë™ ê³„íš'ìœ¼ë¡œ ìˆ˜ì •í•˜ì„¸ìš”.")
                score -= 3
            
            if "ìœ„ì¥ ê²°í˜¼" in narrative or "ëˆì„ ë°›ê³ " in narrative:
                issues.append("ìœ„ì¥ê²°í˜¼ì„ ì•”ì‹œí•˜ëŠ” í‘œí˜„ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                suggestions.append("ì§„ì •í•œ êµì œ ê³¼ì •ì„ ì„¤ëª…í•˜ì„¸ìš”.")
                score -= 5
            
            return {
                "is_valid": len(issues) == 0,
                "score": max(1, score),
                "issues": issues,
                "suggestions": suggestions,
                "improved_version": None if len(issues) == 0 else "AIê°€ ê°œì„ ëœ ë²„ì „ì„ ì œì•ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            }
            
        except Exception as e:
            return {
                "is_valid": False,
                "score": 0,
                "issues": [f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"],
                "suggestions": [],
                "improved_version": None
            }
    
    def generate_narrative(self, generation_prompt: str, user_data: Dict) -> str:
        """
        ì‚¬ì—° ë‚´ìš© ìë™ ìƒì„±
        
        Args:
            generation_prompt: ìƒì„± í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
            user_data: ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°
            
        Returns:
            ìƒì„±ëœ ì‚¬ì—° í…ìŠ¤íŠ¸
        """
        try:
            # í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©ì ë°ì´í„° ì‚½ì…
            formatted_prompt = generation_prompt.format(**user_data)
            
            # =================================================================
            # ì‹¤ì œ OpenAI ì—°ë™ ì½”ë“œ (ë°°í¬ ì‹œ í™œì„±í™”)
            # =================================================================
            """
            system_prompt = '''
            ë‹¹ì‹ ì€ í•œêµ­ ì¶œì…êµ­ê´€ë¦¬ì‚¬ë¬´ì†Œì— ì œì¶œí•  ì„œë¥˜ë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
            ë‹¤ìŒ ì›ì¹™ì„ ì§€ì¼œì£¼ì„¸ìš”:
            1. ì§„ì •ì„± ìˆê³  ì„¤ë“ë ¥ ìˆê²Œ ì‘ì„±
            2. êµ¬ì²´ì ì¸ ë‚ ì§œ, ì¥ì†Œ, ì—í”¼ì†Œë“œ í¬í•¨
            3. í–‰ì •ì ìœ¼ë¡œ ì í•©í•œ í‘œí˜„ ì‚¬ìš©
            4. í•œêµ­ì–´ ì¡´ëŒ“ë§ ì‚¬ìš©
            '''
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": formatted_prompt}
                ],
                max_tokens=2000
            )
            
            return response.choices[0].message.content
            """
            # =================================================================
            # ê°œë°œìš© ëª©ì—… ì½”ë“œ
            # =================================================================
            return f"""
[AI ìƒì„± ì˜ˆì‹œ]

ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ. ì €ëŠ” {user_data.get('nationality', 'ì™¸êµ­')} êµ­ì ì˜ {user_data.get('given_name', 'ì‹ ì²­ì¸')}ì…ë‹ˆë‹¤.

ë³¸ ì„œë¥˜ë¥¼ í†µí•´ ì œ ìƒí™©ê³¼ ê³„íšì„ ë§ì”€ë“œë¦¬ê³ ì í•©ë‹ˆë‹¤.

{user_data.get('narrative_content', '(ìƒì„¸ ë‚´ìš©ì´ ì—¬ê¸°ì— ìƒì„±ë©ë‹ˆë‹¤.)')}

ê°ì‚¬í•©ë‹ˆë‹¤.

---
â€» ì´ê²ƒì€ AIê°€ ìƒì„±í•œ ì´ˆì•ˆì…ë‹ˆë‹¤. ì‹¤ì œ ì œì¶œ ì „ ë°˜ë“œì‹œ ê²€í† í•˜ì„¸ìš”.
            """
            
        except Exception as e:
            return f"ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def chat_response(self, user_message: str, chat_history: List[Dict], rag_context: str = "") -> str:
        """
        AI ì±„íŒ… ì‘ë‹µ ìƒì„±
        
        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            chat_history: ì´ì „ ëŒ€í™” ê¸°ë¡
            rag_context: RAGë¡œ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸
            
        Returns:
            AI ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        try:
            # =================================================================
            # ì‹¤ì œ OpenAI ì—°ë™ ì½”ë“œ (ë°°í¬ ì‹œ í™œì„±í™”)
            # =================================================================
            """
            system_prompt = f'''
            ë‹¹ì‹ ì€ K-Stayì˜ AI ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
            ì™¸êµ­ì¸ì˜ í•œêµ­ ì²´ë¥˜, ë¹„ì, ì¶œì…êµ­ ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.
            
            ì°¸ê³  ìë£Œ:
            {rag_context}
            
            ì›ì¹™:
            1. ì •í™•í•˜ê³  ìµœì‹  ì •ë³´ ì œê³µ
            2. ë¶ˆí™•ì‹¤í•œ ê²½ìš° í•˜ì´ì½”ë¦¬ì•„ í™•ì¸ ê¶Œì¥
            3. ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…
            4. í•„ìš”ì‹œ ì˜ì–´ ë³‘í–‰ ì‚¬ìš©
            '''
            
            messages = [{"role": "system", "content": system_prompt}]
            
            # ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶”ê°€
            for msg in chat_history[-10:]:  # ìµœê·¼ 10ê°œ ëŒ€í™”ë§Œ
                messages.append({"role": msg["role"], "content": msg["content"]})
            
            messages.append({"role": "user", "content": user_message})
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=1500
            )
            
            return response.choices[0].message.content
            """
            # =================================================================
            # ê°œë°œìš© ëª©ì—… ì½”ë“œ
            # =================================================================
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì‘ë‹µ
            user_lower = user_message.lower()
            
            if "d-10" in user_lower or "êµ¬ì§" in user_lower:
                return """
D-10 ë¹„ì (êµ¬ì§ ë¹„ì)ì— ëŒ€í•´ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤.

ğŸ“‹ **ìê²© ìš”ê±´**
- í•™ì‚¬ ì´ìƒ í•™ìœ„ ì†Œì§€ì
- í•œêµ­ ë‚´ ëŒ€í•™ ì¡¸ì—…ì ë˜ëŠ” í•´ì™¸ ëŒ€í•™ ì¡¸ì—… í›„ í•œêµ­ì–´ ëŠ¥ë ¥ ë³´ìœ ì

ğŸ“ **í•„ìš” ì„œë¥˜**
1. í†µí•©ì‹ ì²­ì„œ
2. êµ¬ì§í™œë™ê³„íšì„œ
3. ì—¬ê¶Œ ì‚¬ë³¸
4. ì¡¸ì—…ì¦ëª…ì„œ
5. ì„±ì ì¦ëª…ì„œ

â° **ì²´ë¥˜ ê¸°ê°„**
- ìµœëŒ€ 6ê°œì›” (1íšŒ ì—°ì¥ ê°€ëŠ¥, ì´ 1ë…„)

ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸ˜Š
                """
            
            elif "ì‹œê°„ì œ" in user_lower or "ì•„ë¥´ë°”ì´íŠ¸" in user_lower:
                return """
ì‹œê°„ì œ ì·¨ì—… (ì•„ë¥´ë°”ì´íŠ¸)ì— ëŒ€í•´ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤.

ğŸ“‹ **í—ˆê°€ ì¡°ê±´**
- D-2 (ìœ í•™), D-4 (ì—°ìˆ˜) ë¹„ì ì†Œì§€ì
- ì…êµ­ í›„ 6ê°œì›” ê²½ê³¼
- ì§ì „ í•™ê¸° ì¶œì„ë¥  90% ì´ìƒ

â° **ê·¼ë¬´ ì‹œê°„ ì œí•œ**
- í•™ê¸° ì¤‘: ì£¼ 20ì‹œê°„ ì´ë‚´
- ë°©í•™ ì¤‘: ë¬´ì œí•œ

ğŸš« **ê¸ˆì§€ ì—…ì¢…**
- ìœ í¥ì—…ì†Œ, ì‚¬í–‰ì„± ì—…ì†Œ
- ë‹¨ìˆœ ë…¸ë¬´ (ì œì¡°ì—… ìƒì‚°ì§ ë“±)

í•„ìš”í•œ ì„œë¥˜ë¥¼ K-Stayì—ì„œ ìë™ìœ¼ë¡œ ìƒì„±í•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤!
                """
            
            elif "f-6" in user_lower or "ê²°í˜¼" in user_lower:
                return """
F-6 ê²°í˜¼ì´ë¯¼ ë¹„ìì— ëŒ€í•´ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤.

ğŸ’ **ìê²© ìš”ê±´**
- í•œêµ­ì¸ê³¼ ë²•ì  í˜¼ì¸ ìƒíƒœ
- ê¸°ë³¸ í•œêµ­ì–´ ì†Œí†µ ëŠ¥ë ¥ ë˜ëŠ” ê²°í˜¼ì´ë¯¼ì í”„ë¡œê·¸ë¨ ì´ìˆ˜

ğŸ“ **ì£¼ìš” ì„œë¥˜**
1. í†µí•©ì‹ ì²­ì„œ
2. ê²°í˜¼ë°°ê²½ ì§„ìˆ ì„œ (ë§¤ìš° ì¤‘ìš”!)
3. ë°°ìš°ì ì´ˆì²­ì¥
4. í˜¼ì¸ê´€ê³„ì¦ëª…ì„œ
5. ì†Œë“ì¦ëª… ì„œë¥˜

ğŸ’¡ **Tip**
ê²°í˜¼ë°°ê²½ ì§„ìˆ ì„œëŠ” ì§„ì •ì„±ì´ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.
K-Stayì—ì„œ AIê°€ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤!
                """
            
            else:
                return f"""
ì•ˆë…•í•˜ì„¸ìš”! K-Stay AI ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ğŸ˜Š

"{user_message}"ì— ëŒ€í•´ ë‹µë³€ë“œë¦½ë‹ˆë‹¤.

ì¶œì…êµ­ ê´€ë ¨ ë¬¸ì˜ëŠ” ë‹¤ìŒ ì£¼ì œë“¤ì„ ë‹¤ë£¹ë‹ˆë‹¤:
- ë¹„ì ì¢…ë¥˜ ë° ìš”ê±´ (D-10, F-6, E-7 ë“±)
- ì‹œê°„ì œ ì·¨ì—… í—ˆê°€
- ì²´ë¥˜ìê²© ë³€ê²½/ì—°ì¥
- í•„ìš” ì„œë¥˜ ì•ˆë‚´

êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ì•ˆë‚´ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤!

ğŸ“ ê¸´ê¸‰ ë¬¸ì˜: í•˜ì´ì½”ë¦¬ì•„ 1345
ğŸŒ ê³µì‹ ì‚¬ì´íŠ¸: www.hikorea.go.kr
                """
            
        except Exception as e:
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


class RAGService:
    """RAG (Retrieval-Augmented Generation) ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        """RAG ì´ˆê¸°í™”"""
        # ì‹¤ì œ ë°°í¬ ì‹œ: Vector DB ì—°ê²°
        # self.vector_store = None
        self.knowledge_base = self._load_knowledge_base()
    
    def _load_knowledge_base(self) -> Dict:
        """ì§€ì‹ ë² ì´ìŠ¤ ë¡œë“œ"""
        # =================================================================
        # ì‹¤ì œ ë°°í¬ ì‹œ: Vector DBì—ì„œ ë¡œë“œ ë˜ëŠ” íŒŒì¼ì—ì„œ ë¡œë“œ
        # =================================================================
        # ê°œë°œìš© ìƒ˜í”Œ ì§€ì‹ ë² ì´ìŠ¤
        return {
            "visa_types": {
                "D-10": {
                    "name": "êµ¬ì§ë¹„ì",
                    "duration": "6ê°œì›” (ì—°ì¥ ê°€ëŠ¥)",
                    "requirements": ["í•™ì‚¬ ì´ìƒ", "í•œêµ­ ëŒ€í•™ ì¡¸ì—… ë˜ëŠ” í•œêµ­ì–´ ëŠ¥ë ¥"],
                    "documents": ["í†µí•©ì‹ ì²­ì„œ", "êµ¬ì§í™œë™ê³„íšì„œ", "ì¡¸ì—…ì¦ëª…ì„œ"]
                },
                "F-6": {
                    "name": "ê²°í˜¼ì´ë¯¼",
                    "duration": "1~3ë…„",
                    "requirements": ["í•œêµ­ì¸ ë°°ìš°ì", "í•œêµ­ì–´ ê¸°ë³¸ ì†Œí†µ"],
                    "documents": ["í†µí•©ì‹ ì²­ì„œ", "ê²°í˜¼ë°°ê²½ì§„ìˆ ì„œ", "í˜¼ì¸ê´€ê³„ì¦ëª…ì„œ"]
                },
                "E-7": {
                    "name": "íŠ¹ì •í™œë™",
                    "duration": "1~3ë…„",
                    "requirements": ["ì „ë¬¸ì¸ë ¥", "ê³ ìš©ê³„ì•½"],
                    "documents": ["í†µí•©ì‹ ì²­ì„œ", "ê³ ìš©ê³„ì•½ì„œ", "í•™ë ¥ì¦ëª…"]
                }
            },
            "common_rejections": [
                "ì„œë¥˜ ë¯¸ë¹„ ë˜ëŠ” ë¶ˆì¶©ë¶„",
                "êµ¬ì§ê³„íšì˜ êµ¬ì²´ì„± ë¶€ì¡±",
                "ì†Œë“ ìš”ê±´ ë¯¸ì¶©ì¡±",
                "ê²°í˜¼ì˜ ì§„ì •ì„± ì˜ì‹¬"
            ],
            "tips": [
                "ì„œë¥˜ëŠ” ìµœì†Œ 2ì£¼ ì „ ì¤€ë¹„ ì‹œì‘",
                "ë²ˆì—­ ì„œë¥˜ëŠ” ê³µì¦ í•„ìš”",
                "ì ‘ìˆ˜ ì „ ì„œë¥˜ ì ê²€í‘œ í™•ì¸"
            ]
        }
    
    def retrieve_context(self, query: str, top_k: int = 3) -> str:
        """
        ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            
        Returns:
            ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸
        """
        try:
            # =================================================================
            # ì‹¤ì œ Vector DB ì—°ë™ ì½”ë“œ (ë°°í¬ ì‹œ í™œì„±í™”)
            # =================================================================
            """
            # Pinecone / FAISS / Weaviate ë“± ì‚¬ìš©
            from sentence_transformers import SentenceTransformer
            
            model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
            query_embedding = model.encode(query)
            
            # Vector DB ê²€ìƒ‰
            results = self.vector_store.search(query_embedding, top_k=top_k)
            
            context = "\n\n".join([r.text for r in results])
            return context
            """
            # =================================================================
            # ê°œë°œìš© ëª©ì—… ì½”ë“œ: í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰
            # =================================================================
            context_parts = []
            query_lower = query.lower()
            
            # ë¹„ì íƒ€ì… ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
            for visa_code, visa_info in self.knowledge_base["visa_types"].items():
                if visa_code.lower() in query_lower or visa_info["name"] in query:
                    context_parts.append(f"""
[{visa_code} - {visa_info['name']}]
- ì²´ë¥˜ ê¸°ê°„: {visa_info['duration']}
- ìš”ê±´: {', '.join(visa_info['requirements'])}
- í•„ìš” ì„œë¥˜: {', '.join(visa_info['documents'])}
                    """)
            
            # ì¼ë°˜ íŒ ì¶”ê°€
            if not context_parts:
                context_parts.append(f"""
[ì¼ë°˜ ì•ˆë‚´]
- ì£¼ìš” ê±°ì ˆ ì‚¬ìœ : {', '.join(self.knowledge_base['common_rejections'][:2])}
- íŒ: {self.knowledge_base['tips'][0]}
                """)
            
            return "\n".join(context_parts)
            
        except Exception as e:
            return f"ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"


class NarrativeValidator:
    """ì‚¬ì—° ê²€ì¦ í—¬í¼ í´ë˜ìŠ¤"""
    
    @staticmethod
    def render_validation_result(result: Dict):
        """ê²€ì¦ ê²°ê³¼ UI ë Œë”ë§"""
        
        if result["is_valid"]:
            st.success(f"âœ… ê²€í†  ì™„ë£Œ! ì ìˆ˜: {result['score']}/10")
        else:
            st.warning(f"âš ï¸ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. ì ìˆ˜: {result['score']}/10")
        
        # ë¬¸ì œì  í‘œì‹œ
        if result.get("issues"):
            st.markdown("### ğŸ” ë°œê²¬ëœ ë¬¸ì œ")
            for issue in result["issues"]:
                st.markdown(f"- âŒ {issue}")
        
        # ê°œì„ ì  í‘œì‹œ
        if result.get("suggestions"):
            st.markdown("### ğŸ’¡ ê°œì„  ì œì•ˆ")
            for suggestion in result["suggestions"]:
                st.markdown(f"- ğŸ’¡ {suggestion}")
        
        # ê°œì„ ëœ ë²„ì „ ì œì•ˆ
        if result.get("improved_version"):
            with st.expander("ğŸ“ AI ê°œì„  ë²„ì „ ë³´ê¸°"):
                st.markdown(result["improved_version"])
                if st.button("ì´ ë²„ì „ ì‚¬ìš©í•˜ê¸°"):
                    return result["improved_version"]
        
        return None
